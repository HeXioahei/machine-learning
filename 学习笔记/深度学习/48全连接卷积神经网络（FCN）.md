*代码实现：[machine-learning/代码实现/FCN.ipynb at master · HeXioahei/machine-learning (github.com)](https://github.com/HeXioahei/machine-learning/blob/master/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/FCN.ipynb)*

# 用途
FCN是用深度神经网络来做**语义分割**的奠基性工具。

# 原理及实现方法
它用**转置卷积层**来替换CNN最后的全连接层，从而可以实现每个像素的预测。

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202410091730376.png)

简单概括来说就是，先进行CNN操作，提取出图像的特征，得到浓缩后的特征图，再通过转置卷积把特征图放大回原来图片的大小，这样就把特征映射回了原来图片上，相当于直接在原图上进行了特征分割。

所以关键就在于转置卷积层，用来对特征图进行放大。
## 什么是转置卷积？

优质文章：[一文搞懂反卷积，转置卷积_反卷积和转置卷积-CSDN博客](https://blog.csdn.net/LoseInVain/article/details/81098502)

正常的卷积是“多对一”的一种映射关系，实现的是“大变小”的作用，而转置卷积是“一对多”的一种映射关系，实现的是“小变大”的作用。
正常卷积的计算公式为：新宽 = （原宽 + 填充×2 - 卷积核边长）/ 步长 + 1。简单表示为：$d2=(d1+2p-k)/s+1$ （这里的 $/$ 是整除）。
反推一下即可知道，转置卷积的计算公式为：新宽 = （原宽 - 1）× 步长 + 卷积核边长 - 填充 × 2。简单表示为：$d2=(d1-1)×s+k-2p$ 。

# 优缺点
* **优点**：FCN能够在不同尺度和不同比例下进行特征提取和分类，能够更好地处理多尺度目标；同时，由于其全卷积结构，能够得到像素级的分类结果，输出与输入尺寸相同，可以直接应用于图像分割等任务。
* **缺点**：FCN得到的结果还不够精细，对细节不够敏感；同时，没有考虑像素与像素之间的关系，缺乏空间一致性等。