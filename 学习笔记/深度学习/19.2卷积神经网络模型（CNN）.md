> 课程：[【数之道 08】走进"卷积神经网络"，了解图像识别背后的原理_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1R5411w715/?spm_id_from=333.788&vd_source=327f3e87e497fe83b3515199232efd15)

（卷积层里的通道数是不是就对应着全连接层里的维度？）（好像是这样的）

——不，并不是这样的。卷积层的输出通道数是由卷积核的数量决定的，而全连接层的输入维度是由上一层的输出维度决定的。一个卷积核里有和输入通道数相同数目的卷积面，它们分别进行对应的卷积求和操作，得到的缩小的面再进行相加，就得到了一个新的输出通道，也就对应着一张新的特征图。图片有几个特征，一个卷积层里就会有几个卷积核，也就会有相应多个输出通道，产生产生相应多个特征图。这些图最后进行扁平化处理，变成一个一维向量，而全连接层的输入正是这个向量。就这样输入全连接层，最终根据需求决定全连接层的输出通道个数，进行输出。

用CNN来判断一张图片的类别，过程分解：
以判断一张数字图片是哪个数字为例，如下图（一张`6*6`的表示数字7的像素图）：

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202410091935968.png)

## 第一步：提取图片特征

要用到**卷积核**，也可以称为**特征过滤器**，用来**提取图片特征**。通常，这里的卷积核会是一个`3*3`的像素图，也被称为`3*3卷积核`。在此例中，为了分别代表垂直特征和水平特征的这两个特征，所以用了两个卷积核。因为输入只有一张图片，即只有一张像素图，i相当于输入通道数为1，所以每个卷积核中只有一张卷积面，也即只有一张像素图。

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202410091936366.png)![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202410091937809.png)

然后就是根据卷积的计算公式进行**特征提取计算**，最终得到新的`4*4`的像素图，也即**特征图**。

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202410091940759.png)

有两个卷积核，显然就会产生两张特征图，在图中，我们可以根据像素数字的大小来设置颜色的深浅。

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202410091953993.png)![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202410091953266.png)

如图，从左到右分别是垂直特征卷积和水平特征卷积得到的特征图。可以看得出来，垂直特征被很好地提取出来了，但是水平特征却并不明显，没有被提取出来。
这是为什么呢？因为原图中水平的1在**边缘**，而在特征提取计算的过程中，图片会变小，这样边缘的特征就消失了。
所以，为了解决这一问题，我们会使用“**padding扩充法**”。把卷积面的行列数（称为kernel_size）记为`k`，在步长（stride）为1的情况下，若`k`是奇数，则`padding`应该=`(k-1)/2`，若 k 是偶数，则`padding`应该=`k/2`。在此例中，`k`=3，所以`padding`=1，设置padding=1，则会把原来的6×6扩充为8×8，扩充部分的像素值均设置为0。这样在特征提取计算之后，得到的特征图像素仍然为6×6，垂直和水平特征就都可以得到完美的提取。

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202410092017717.png)
![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202410092002684.png)![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202410092003918.png)

## 第二步：最大池化（max pooling）
此过程的目的是将图片的数据进一步压缩，仅反应特征图中“**最突出**”的特点。我们用2×2的网格将6×6的特征图**分割**为3×3个部分，然后提取每个部分中的**最大值**，分别对应地放入池化后的3×3的网格中，池化后的数据保留了原始图片中最精华的特征部分。

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202410092009382.png) --->![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202410092009752.png)

## 第三步：扁平化处理
将池化后的数据进行扁平化处理，将两个3×3的像素图叠加，转换成**1维的数据“条”**

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202410092019168.png)

数据条录入到后面的**全连接隐藏层**，然后就是ANN所要做的事了

![image.png](https://youki-1330066034.cos.ap-guangzhou.myqcloud.com/machine-learning/202410092019578.png)
## 第四步：输出结果
我们可以用sigmoid函数来得到一个概率，判断是否为某个事物，比如在此例中，可以输出一个判断是7的概率。也可以用softmax来输出每种数字的可能性概率。

至此，CNN就完成了他的使命啦！

一个非常棒的演示CNN过程的在线工具——CNN Explainer，网址为：[poloclub.github.oi](https://poloclub.github.oi/cnn-explainer/)（不过我打不开）

