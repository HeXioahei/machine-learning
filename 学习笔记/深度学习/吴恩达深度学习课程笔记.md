# logistic回归
## logistic回归
用于解决二分类问题，使得输出结果在0到1之间，满足概率的形式。就是在线性函数的结果再放入sigmoid函数中进行激活。

## logistic回归损失函数
为了训练logistic回归模型的参数w和b，我们需要再定义一个成本函数（代价函数）（cost function）。现在我们来看看用logistic回归来训练的损失函数（误差函数）（loss function）。

最简单一种损失函数L的定义方式是，y_hat 与 y 的差的平方，但是这种定义方式在梯度下降法寻找最小值时效果往往不好，因为它可能存在很多局部最优解（即很多极小值）。所以我们要定义一个不一样的损失函数。人们往往是这样定义的：

$$L(y,\hat{y})=-(ylog\hat{y}+(1-y)log(1-\hat{y}))$$

为什么说这个函数的作用效果就比较好呢？我们取两个特殊的情况来看看。

如果y=1，我们想让L尽可能小，根据函数，就需要y_hat尽可能大。而y_hat是经过sigmoid处理过后的，所以它不会大过1，它就算再大也只会无限地接近于1，也就是，无限地接近于y，这正是我们想要的效果，y_hat很接近y，预测效果越准确。

如果y=0，我们想让L尽可能小，根据函数，就需要y_hat尽可能小。而y_hat是经过sigmoid处理过后的，所以它不会小过0，它就算再小也只会无限地接近于0，也就是，无限地接近于y，这正是我们想要的效果，y_hat很接近y，预测效果越准确。